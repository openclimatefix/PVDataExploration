{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime, date, timedelta\n",
    "from typing import Dict, List, Tuple, Union\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "\n",
    "def find_files(\n",
    "    filename: str  = None, \n",
    "    search_path:str = None,\n",
    "    print_bool: bool = False\n",
    "    )-> None:\n",
    "    \"\"\"\n",
    "    Find any file and returns the filename and its path\n",
    "    Args:\n",
    "    filename = filename to be searched for \n",
    "    search_path = directory of the Searching path\n",
    "    \"\"\"\n",
    "    dir_path = None\n",
    "    for root, dir, files in os.walk(search_path):\n",
    "        if filename in files:\n",
    "            dir_path = Path(os.path.join(root, filename)).parent.as_posix()\n",
    "    if dir_path not in sys.path:\n",
    "        sys.path.append(dir_path)\n",
    "    file_path = Path(os.path.join(dir_path, filename)).as_posix()\n",
    "    if print_bool:\n",
    "        print(\"\\nPath to your file is :\\n\", file_path)\n",
    "        print(\"\\nDirectory of that file is:\\n\", dir_path)\n",
    "        return dir_path, file_path\n",
    "    else:\n",
    "        return dir_path, file_path\n",
    "\n",
    "def create_dir(\n",
    "    working_dir:str = None,\n",
    "    dir_name:str = None\n",
    "    )->None:\n",
    "    \"\"\"\n",
    "    A function to create a directory and attach that \n",
    "    to the working directory\n",
    "    Args:\n",
    "    working_dir = Wokrking directory\n",
    "    dir_name = Name of the directory needed to be created\n",
    "    \"\"\"\n",
    "    dir = os.path.join(Path(working_dir).as_posix(), dir_name)\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir, exist_ok = True)\n",
    "    return dir\n",
    "\n",
    "def download_zip_url(\n",
    "    zip_file_url: str = None,\n",
    "    path_to_save:str = None\n",
    "    )->None:\n",
    "    \"\"\"\n",
    "    A function to download a zip file from the url\n",
    "    and save it in a specified folder\n",
    "    Args:\n",
    "    zip_file_url = url of the zip file\n",
    "    path_to_save = A path of the folder to which\n",
    "    the zip files are going to be extracted to\n",
    "    \"\"\"\n",
    "    #Downloading and extracting\n",
    "    print(\"\\nDownloading the zip files...........\\n\")\n",
    "    with requests.get(zip_file_url, stream = True) as r:\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        print(\"\\nDownload complete.......................\\n\")\n",
    "        print(\"\\nBegin Extracting the files in zip..........\\n\")\n",
    "        z.extractall(path = path_to_save)\n",
    "        print(\"\\nExtraction complete............\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataops():\n",
    "    def __init__(\n",
    "        self,\n",
    "        downloads_path:Path[Union, str],\n",
    "        metafilename:str,\n",
    "        netcdffilename:str)->None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        downloads_path = Set the path where the downloaded meta and netcdf files are\n",
    "        metafilename = input the metadata file name inclusing extension(.csv)\n",
    "        netcdffilename = as suggested above including the extension(.netcdf)\n",
    "        \"\"\"        \n",
    "        #Setting the path and loading the datasets\n",
    "        # downlods_path = Path(r\"c:\\\\Users\\\\vardh\\\\OneDrive - University of Leicester\\\\OCF\\\\Git_repos\\\\downloads\")\n",
    "        self.downloads_path = downloads_path\n",
    "        self.metafilename = metafilename\n",
    "        self.netcdffilename = netcdffilename\n",
    "        self.uk_pv_meta_path = Path(os.path.join(self.downloads_path, self.metafilename))\n",
    "        self.uk_pv_netcdf_path = Path(os.path.join(self.downloads_path, self.netcdffilename)) \n",
    "    \n",
    "    def load_data(self)->None:\n",
    "        \"\"\"\n",
    "        Reading the data into variables\n",
    "        \"\"\"\n",
    "        dataops.metadata_df = pd.read_csv(self.uk_pv_meta_path.as_posix())\n",
    "        dataops.pv_power = xr.open_dataset(self.uk_pv_netcdf_path.as_posix(), engine=\"h5netcdf\")\n",
    "\n",
    "    def dates_list(self)->None:\n",
    "        \"\"\"\n",
    "        Converts dates as coorniates from xarray dataset to a list\n",
    "        \"\"\"\n",
    "        self.dates_lst = dataops.pv_power.coords[\"datetime\"].values\n",
    "        self.dates_lst = [pd.to_datetime(str(i))for i in self.dates_lst]\n",
    "        self.dates_lst = [i.strftime('%Y-%m-%d') for i in self.dates_lst]\n",
    "        dataops.dates_lst = list(set(self.dates_lst))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    downloads_path = r\"c:\\\\Users\\\\vardh\\\\OneDrive - University of Leicester\\\\OCF\\\\Git_repos\\\\downloads\\\\huggingface_uk_pv\"\n",
    "    metafilename = \"uk_pv_metadata.csv\"\n",
    "    netcdffilename = \"uk_pv_netcdf.netcdf\"\n",
    "    dops = dataops(\n",
    "        downloads_path = downloads_path,\n",
    "        metafilename = metafilename,\n",
    "        netcdffilename = netcdffilename        \n",
    "    )\n",
    "    dops.load_data()\n",
    "    dops.dates_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class xr_df:\n",
    "    def __init__(\n",
    "        self,\n",
    "        date_oi:str,\n",
    "        ssid:str):\n",
    "        self.date_oi = date_oi\n",
    "        self.ssid = ssid\n",
    "\n",
    "    @staticmethod                \n",
    "    def xr_to_df(\n",
    "        date_oi:str,\n",
    "        ssid:str):\n",
    "        \"\"\"\n",
    "        converts xarray dataset into a pandas dataframe, and its values for a single day\n",
    "        Args:\n",
    "        date_oi = Date of Interest\n",
    "        ssid = ID of the PV system\n",
    "        \"\"\"\n",
    "        # self.date_oi = \"2021-10-24\"     \n",
    "        date_1 = datetime.strptime(date_oi, '%Y-%m-%d')\n",
    "        next_day = date_1+timedelta(days=1)\n",
    "        on_pv_system = dataops.pv_power[ssid].to_dataframe()\n",
    "        on_pv_system = on_pv_system[(on_pv_system.index < next_day)&(on_pv_system.index > date_1)]\n",
    "        xr_df.on_pv_system = on_pv_system\n",
    "        return on_pv_system\n",
    "\n",
    "    def display(\n",
    "        self)->None:\n",
    "        \"\"\"\n",
    "        Plot the PV output of the day that is randomly selected with SSID and a date\n",
    "        \"\"\"\n",
    "        fig = plt.figure()\n",
    "        plt.plot(xr_df.on_pv_system)\n",
    "        fig.suptitle(\"One-day PV output time-series\", fontsize = 10)\n",
    "        plt.ylabel('Power output KWh', fontsize = 10)\n",
    "        plt.xlabel(self.date_oi, fontsize = 10)\n",
    "        plt.xticks([])\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    ssid = random.choice(list(dataops.pv_power))\n",
    "    # ssid = \"26797\"\n",
    "    date_oi = random.choice(list(dataops.dates_lst))\n",
    "    # date_oi = \"2018-06-21\"\n",
    "    print(\"Randomly selected date is\", date_oi) \n",
    "    print(\"Randomly selected SSID is \", ssid)    \n",
    "    xrdf = xr_df(\n",
    "        date_oi = date_oi,\n",
    "        ssid = ssid)\n",
    "    xrdf.xr_to_df(\n",
    "        date_oi = date_oi,\n",
    "        ssid = ssid        \n",
    "    )\n",
    "    xrdf.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class no_pv_output:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ssid_list:List,\n",
    "        dates_list:List\n",
    "    )->None:\n",
    "        self.ssid_list = ssid_list\n",
    "        self.dates_list = dates_list\n",
    "    \n",
    "    @staticmethod\n",
    "    def no_pv_df(\n",
    "        ssid_list:List,\n",
    "        dates_list:List\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This function gives a pandas dataframe that stores \n",
    "        all the SSID with corresponding dates with no PV output\n",
    "        Args:\n",
    "        ssid_list = List of the ssid's of the PV systems\n",
    "        dates_list = List of the dates that are of interest\n",
    "        \"\"\"\n",
    "        no_pv_df = pd.DataFrame()\n",
    "        for i in ssid_list:\n",
    "            for j in dates_list:\n",
    "                df = xr_df.xr_to_df(date_oi=j,ssid=i)\n",
    "                df_values = df.values\n",
    "                torf = np.isnan(df_values).all()\n",
    "                if torf == False:\n",
    "                    continue\n",
    "                temp = pd.DataFrame(\n",
    "                    {\n",
    "                        'ssid': i,\n",
    "                        'date':j\n",
    "                    }, index = [0]\n",
    "                )\n",
    "                no_pv_df = pd.concat([no_pv_df, temp])\n",
    "        return no_pv_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ssid_list = list(dataops.pv_power)\n",
    "    ssid_list = [\"26797\"]\n",
    "    # dates_list = dataops.dates_lst\n",
    "    dates_list = [\"2020-12-01\"]\n",
    "    npo = no_pv_output(\n",
    "        ssid_list = ssid_list,\n",
    "        dates_list = dates_list        \n",
    "    )\n",
    "    npo.no_pv_df(\n",
    "        ssid_list = ssid_list,\n",
    "        dates_list = dates_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vardh\\OneDrive - University of Leicester\\OCF\\Git_repos\\PVDataExploration\\eda\\uk_pv_eda.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vardh/OneDrive%20-%20University%20of%20Leicester/OCF/Git_repos/PVDataExploration/eda/uk_pv_eda.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vardh/OneDrive%20-%20University%20of%20Leicester/OCF/Git_repos/PVDataExploration/eda/uk_pv_eda.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m data \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mhttps://opendata.arcgis.com/datasets/69dc11c7386943b4ad8893c45648b1e1_0.geojson\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vardh/OneDrive%20-%20University%20of%20Leicester/OCF/Git_repos/PVDataExploration/eda/uk_pv_eda.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m lad_gdf \u001b[39m=\u001b[39m gpd\u001b[39m.\u001b[39;49mGeoDataFrame\u001b[39m.\u001b[39;49mfrom_features(data\u001b[39m.\u001b[39;49mjson(),crs\u001b[39m=\u001b[39;49m\u001b[39m4326\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vardh/OneDrive%20-%20University%20of%20Leicester/OCF/Git_repos/PVDataExploration/eda/uk_pv_eda.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m lad_gdf\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\vardh\\Anaconda3\\envs\\pv_data_eda\\lib\\site-packages\\geopandas\\geodataframe.py:635\u001b[0m, in \u001b[0;36mGeoDataFrame.from_features\u001b[1;34m(cls, features, crs, columns)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(feature, \u001b[39m\"\u001b[39m\u001b[39m__geo_interface__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    633\u001b[0m     feature \u001b[39m=\u001b[39m feature\u001b[39m.\u001b[39m__geo_interface__\n\u001b[0;32m    634\u001b[0m row \u001b[39m=\u001b[39m {\n\u001b[1;32m--> 635\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m: shape(feature[\u001b[39m\"\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mif\u001b[39;00m feature[\u001b[39m\"\u001b[39;49m\u001b[39mgeometry\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    636\u001b[0m }\n\u001b[0;32m    637\u001b[0m \u001b[39m# load properties\u001b[39;00m\n\u001b[0;32m    638\u001b[0m properties \u001b[39m=\u001b[39m feature[\u001b[39m\"\u001b[39m\u001b[39mproperties\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "#IGNORE\n",
    "#######\n",
    "\n",
    "class no_pv_output():\n",
    "    def __init__(self)->None:\n",
    "        \"\"\"\"\"\"\n",
    "        pass\n",
    "    @staticmethod\n",
    "    def no_pv_dict():\n",
    "\n",
    "        ssid_list = list(dataops.pv_power)\n",
    "        ssid_list = [\"10003\"]\n",
    "        no_pv_dict = {}\n",
    "        for i in ssid_list:\n",
    "            no_pv_dict[i] = None\n",
    "        for key in no_pv_dict:\n",
    "            ssid_pv_df = dataops.pv_power[key].to_dataframe()\n",
    "            for j in range(len(xr_df.dates_lst)):\n",
    "                no_pv_dates = []\n",
    "                date_1 = datetime.strptime(xr_df.dates_lst[j], '%Y-%m-%d')\n",
    "                next_day = date_1+timedelta(days=1)\n",
    "                on_pv_system = ssid_pv_df[\n",
    "                    (ssid_pv_df.index < next_day)\n",
    "                    &\n",
    "                    (ssid_pv_df.index > date_1)\n",
    "                    ]                                \n",
    "                torf = np.isnan(on_pv_system.values).all()\n",
    "                # print(torf)\n",
    "                if torf == True:\n",
    "                    # print(date_1,\"has no PV output on this system with ID\", ssid_list[i])\n",
    "                    no_pv_dates.append(xr_df.dates_lst[j])\n",
    "                    pass\n",
    "                print(no_pv_dates)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    npo = no_pv_output()\n",
    "    npo.pv_output()\n",
    "    \n",
    "class check_na():\n",
    "    def __init__(self):\n",
    "        \"\"\"\"\"\"\n",
    "        pass\n",
    "    def iter_xr(self)-> None:\n",
    "        # self.true_false = []\n",
    "        # ssid_lst = list(dataops.pv_power)\n",
    "        # for i in ssid_lst:\n",
    "        #     torf = np.isnan(dataops.pv_power[i].values).all()\n",
    "        #     self.true_false.append(torf)\n",
    "        # print(self.true_false)\n",
    "        ssid_list = list(dataops.pv_power)\n",
    "        print(type(ssid_list))\n",
    "        self.dates_lst = dataops.pv_power.coords[\"datetime\"].values\n",
    "        self.dates_lst = [pd.to_datetime(str(i))for i in self.dates_lst]\n",
    "        self.dates_lst = [i.strftime('%Y-%m-%d') for i in self.dates_lst]\n",
    "        print(type(self.dates_lst))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ckna = check_na()\n",
    "    ckna.iter_xr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pv_data_eda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d005e23926556d8b766634c856ca62b570e3a1b36a4ac7eae16508f00e83ec56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
