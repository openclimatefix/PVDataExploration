{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c0e6a890",
      "metadata": {
        "id": "c0e6a890"
      },
      "source": [
        "#   <u>Satellite Cloud Coverage and Power Generation Visualization</u>\n",
        "\n",
        "\n",
        "## INTRODUCTION\n",
        "\n",
        "This notebook generates a time-lapse video showcasing the movement of clouds across the sky along with the corresponding power generation at each PV system on a daily basis. By combining the satellite-based cloud coverage data from the EUMETSAT Solar Forecasting dataset and the power generation information, the video illustrates the dynamic relationship between cloud movement and the amount of power generated at each PV system.\n",
        "\n",
        "**Data**\n",
        "\n",
        "there are three datasets used for this analysis:\n",
        "\n",
        "\n",
        "- **eumetsat_seviri_hrv_uk.zarr**: The cloud coverage dataset is derived from the EUMETSAT SEVIRI RSS, which covers the northern third of the Meteosat disc and captures images every five minutes.\n",
        "\n",
        "  The dataset used for this analsis,available on Google Cloud, was transformed by Open Climate Fix and is a subset of the   complete SEVIRI RSS dataset. It includes data for the United Kingdom and North Western Europe from January 2020 to November 2021. The original data is protected by copyright held by EUMETSAT. However, EUMETSAT has granted permission for the distribution of this transformed dataset. For more information please read here https://console.cloud.google.com/marketplace/product/bigquery-public-data/eumetsat-seviri-rss-hrv-uk?project=steel-apparatus-318910\n",
        "\n",
        "\n",
        "\n",
        "- **5min parquet**: Time series data of PV solar generation data. Available: https://huggingface.co/datasets/openclimatefix/uk_pv/tree/main. For information about the data read more here https://huggingface.co/datasets/openclimatefix/uk_pv\n",
        "- **metadata**: Metadata of the different PV systems. Available: https://huggingface.co/datasets/openclimatefix/uk_pv/tree/main. Read more here https://huggingface.co/datasets/openclimatefix/uk_pv\n",
        "\n",
        "**Method**\n",
        "\n",
        "- Step 1) Utilizing cloud coverage satellite images from the EUMETSAT Solar Forecasting dataset, extracting the cloud image foreground\n",
        "- Step 2) Superimposing the cloud image it onto the power generation data of each PV system. for a specific time stamp\n",
        "- Step 3) Iterate throught all time stamps in one day ( from 00:00:00 to 23:55:00) and export as HTML\n",
        "- Step 4) take a screen shot of HTML files and export to png\n",
        "- Step 5) Combine the PNG images into a video to create a time-lapse representation of the cloud movement and power generation.\n",
        "\n",
        "## ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b20f79e2",
      "metadata": {
        "id": "b20f79e2"
      },
      "outputs": [],
      "source": [
        "# Installing requiered packages\n",
        "!pip install xarray[complete]\n",
        "!pip install ocf-blosc2\n",
        "!pip install opencv-python\n",
        "!pip install geopandas\n",
        "!pip install pyshp\n",
        "!pip install Pillow\n",
        "!pip install scikit-image\n",
        "!pip install selenium\n",
        "!pip install imgkit\n",
        "!pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca6acb6b",
      "metadata": {
        "id": "ca6acb6b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from shapely.geometry import Point\n",
        "from pyproj import Proj, transform\n",
        "from pyproj import CRS, Transformer\n",
        "from skimage import color, filters\n",
        "import xarray as xr\n",
        "import ocf_blosc2\n",
        "import folium\n",
        "import pyproj\n",
        "import cv2\n",
        "\n",
        "import time\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "import folium"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09055756",
      "metadata": {
        "id": "09055756"
      },
      "source": [
        "### Loading datasets\n",
        "\n",
        "#### REPLACE PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f46e4a7",
      "metadata": {
        "id": "1f46e4a7"
      },
      "outputs": [],
      "source": [
        "# define paths to data\n",
        "math_to_min5 = PATH # REPLACE with path to 5min data\n",
        "math_to_metadata = PATH # REPLACE with path to metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e59de58a",
      "metadata": {
        "id": "e59de58a"
      },
      "outputs": [],
      "source": [
        "# Load the 5min data file and metadata\n",
        "min5 = pd.read_csv(math_to_min5)\n",
        "# Import metadata\n",
        "meta = pd.read_csv(math_to_metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ec42146",
      "metadata": {
        "id": "1ec42146"
      },
      "source": [
        "### Prepairing Data\n",
        "\n",
        "The data will be loaded and cleaned using the following four functions\n",
        "\n",
        "1) The *load_data(time)* function loads the EUMETSAT Solar Forecasting dataset for a specific time.\n",
        "\n",
        "2) The *select_transform(data_in, timestamp)* function selects a specific time slice from the input dataset, converts it to a pandas dataframe, and transforms the coordinate system from OSGB (British National Grid) to WGS84 (latitude and longitude).\n",
        "\n",
        "3) The *pwg_gen_clean(loading_date, loading_time)* function cleans and filters power generation data for a specific date and time. It also merges the filtered data with additional metadata and creates a GeoDataFrame with a geometry column based on latitude and longitude information.\n",
        "\n",
        "4) The *create_map(dataset)* function processes satellite data by creating a cloud mask and generating a transparent cloud image. It then creates a folium map centered around the UK and adds power generation data as circles on the map, with circle size and fill color based on the power generation value. The function overlays the transparent cloud image on the map and saves it as an HTML file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4f977a3",
      "metadata": {
        "id": "f4f977a3"
      },
      "outputs": [],
      "source": [
        "def load_data(time):\n",
        "    'loads the EUMETSAT Solar Forecasting dataset for a specific time'\n",
        "    try:\n",
        "        df = (\n",
        "            xr.open_mfdataset(\n",
        "                \"gs://public-datasets-eumetsat-solar-forecasting/satellite/EUMETSAT/SEVIRI_RSS/v3/eumetsat_seviri_hrv_uk.zarr\",\n",
        "                engine=\"zarr\",\n",
        "                concat_dim=\"time\",\n",
        "                combine=\"nested\",\n",
        "                chunks={},\n",
        "                join=\"override\",\n",
        "            )\n",
        "            .drop_duplicates(\"time\")\n",
        "            .sel(time=time)\n",
        "        )\n",
        "        return df\n",
        "    except KeyError:\n",
        "        return None\n",
        "\n",
        "def select_transform(data_in, timestamp):\n",
        "    #'select a specific time slice from the input dataset, convert the dataset to\n",
        "    #'a pandas dataframe, transforms the coordinate system from OSGB'\n",
        "    #'(British National Grid) to WGS84 (latitude and longitude).'\n",
        "\n",
        "    # Define the input and output coordinate systems\n",
        "    input_crs = CRS.from_epsg(27700)  # OSGB (British National Grid)\n",
        "    output_crs = CRS.from_epsg(4326)  # WGS84 (latitude and longitude)\n",
        "\n",
        "    # Select the specific time slice and extract the data, convert to pandas\n",
        "    data_slice = data_in.to_dataframe()\n",
        "\n",
        "    # Create a transformer to convert between coordinate systems\n",
        "    transformer = Transformer.from_crs(input_crs, output_crs)\n",
        "\n",
        "    # Convert x_osgb and y_osgb to latitude and longitude\n",
        "    data_slice['latitude'], data_slice['longitude'] = transformer.transform(\n",
        "        data_slice['x_osgb'].values.round(2),\n",
        "        data_slice['y_osgb'].values.round(2)\n",
        "    )\n",
        "    return data_slice\n",
        "\n",
        "\n",
        "def pwg_gen_clean(loading_date, loading_time):\n",
        "    'cleans and filters power generation data for a specific date and time'\n",
        "    'merges the filtered data with the metadata and creates a'\n",
        "    'GeoDataFrame with a geometry column based on latitude and longitude'\n",
        "    # Clean the string columns for date and time\n",
        "    min5['date'] = min5['date'].str.strip()\n",
        "    min5['time'] = min5['time'].str.strip()\n",
        "    # Filter for the desired date, this will reduce the size of the dataset\n",
        "    min5_sel = min5[min5['date'] == loading_date]\n",
        "    # Fixing the timestamp\n",
        "    min5_sel.loc[:, 'timestamp'] = pd.to_datetime(min5_sel['time'], format='%H:%M').dt.time\n",
        "    # Add the new column to the dataframe\n",
        "    min5_sel.loc[:, 'timestamp'] = min5_sel['date'].astype('str') + ' ' + min5_sel['timestamp'].astype('str')\n",
        "    # Drop unnecessary columns\n",
        "    min5_sel = min5_sel.drop(['time', 'date'], axis=1)\n",
        "    # Convert timestamp to datetime\n",
        "    min5_sel.loc[:, 'timestamp'] = pd.to_datetime(min5_sel['timestamp'])\n",
        "    # Filter the dataset for the specified time\n",
        "    time2 = time.replace('T', ' ')\n",
        "    filtered_data = min5_sel.loc[min5_sel['timestamp'] == pd.Timestamp(time2)]\n",
        "    # Merging with the 5min data\n",
        "    columns_to_include = ['ss_id', 'latitude_rounded', 'longitude_rounded']\n",
        "    filtered_data_sel = filtered_data.merge(meta[columns_to_include], on='ss_id', how='left')\n",
        "    # Create a geometry column using the latitude and longitude information\n",
        "    geometry = [Point(xy) for xy in zip(filtered_data_sel['longitude_rounded'], filtered_data_sel['latitude_rounded'])]\n",
        "    # Convert the pandas DataFrame to a GeoDataFrame\n",
        "    gdf = gpd.GeoDataFrame(filtered_data_sel, geometry=geometry)\n",
        "    return gdf\n",
        "\n",
        "\n",
        "def create_map(dataset):\n",
        "    #'processes satellite data by creating'\n",
        "    #'a cloud mask and generating a transparent cloud image'\n",
        "    #'creates a folium map centered around the UK and adds power generation data\n",
        "    #'as circles on the map, with circle size and fill color based on the power generation value'\n",
        "    #'Then overlays the transparent cloud image on the map and saves it as an HTML file.'\n",
        "\n",
        "    # Process satellite data\n",
        "    image = np.array(dataset['data'])\n",
        "    image_gray = image.reshape((891, 1843))\n",
        "    image_gray_normalized = image_gray / image_gray.max()\n",
        "    threshold = 0.2\n",
        "    cloud_mask = image_gray_normalized > threshold\n",
        "    cloud_image = image_gray.copy()\n",
        "    cloud_image[~cloud_mask] = 0\n",
        "    transparent_cloud_image = np.zeros((cloud_image.shape[0], cloud_image.shape[1], 4), dtype=np.uint8)\n",
        "    transparent_cloud_image[..., 2] = cloud_image\n",
        "    transparent_cloud_image[..., 3] = cloud_mask.astype(np.uint8) * 255\n",
        "\n",
        "    # Create a folium map centered around the UK\n",
        "    m = folium.Map(location=[54.7023545, -3.2765753], zoom_start=6)\n",
        "\n",
        "    # Get the latitude and longitude range\n",
        "    min_lat, max_lat = dataset['latitude'].min(), dataset['latitude'].max()\n",
        "    min_lon, max_lon = dataset['longitude'].min(), dataset['longitude'].max()\n",
        "\n",
        "    # Add the power generation data as circles on the map\n",
        "    pw_gen_gdf = pwg_gen_clean(loading_date, loading_time)\n",
        "    for i in range(len(pw_gen_gdf)):\n",
        "        power_generation = float(pw_gen_gdf.iloc[i]['generation_wh'])\n",
        "\n",
        "        fill_color = 'grey'\n",
        "        if power_generation < 50:\n",
        "            fill_color = '#4DD0E1'\n",
        "            radius=1000\n",
        "        elif power_generation < 100:\n",
        "            fill_color = '#0097A7'\n",
        "            radius=5000\n",
        "        else:\n",
        "            fill_color = '#006064'\n",
        "            radius=10000\n",
        "\n",
        "        folium.Circle(\n",
        "            location=[pw_gen_gdf.iloc[i]['latitude_rounded'], pw_gen_gdf.iloc[i]['longitude_rounded']],\n",
        "            radius=radius,\n",
        "            color=fill_color,\n",
        "            fill=True,\n",
        "            fill_color=fill_color\n",
        "        ).add_to(m)\n",
        "\n",
        "    # Overlay the transparent cloud image\n",
        "    transparent_cloud_image[..., :3] = 255\n",
        "\n",
        "    folium.raster_layers.ImageOverlay(\n",
        "        image=transparent_cloud_image,\n",
        "        bounds=[[min_lat, min_lon], [max_lat, max_lon]],\n",
        "        opacity=0.7,\n",
        "    ).add_to(m)\n",
        "\n",
        "    # Save the map as an HTML file\n",
        "    valid_time = time.replace(\":\", \"_\")\n",
        "    save_name = f\"map_{valid_time}.html\"\n",
        "    m.save(save_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de3cf0f1",
      "metadata": {
        "id": "de3cf0f1"
      },
      "source": [
        "### RUNNING THE FUNCTIONS\n",
        "\n",
        "This code is performing the following tasks:\n",
        "\n",
        "1) Sets an initial timestamp such as \"2021-04-25T00:00:00\". This value needs to be changed based on the target date\n",
        "\n",
        "2) Enters a loop that iterates through 5-minute intervals until the end of a 24-hour cycle.\n",
        "\n",
        "3) Within each iteration, it extracts the date and time components from the current timestamp.\n",
        "\n",
        "4) Calls the load_data(time) function to load the data for the specified timestamp.\n",
        "\n",
        "5) Checks if the timestamp is present in the loaded dataframe. If not, it moves to the next timestamp by incrementing the time by 5 minutes.\n",
        "\n",
        "6) If the timestamp is found in the dataframe, it calls the pwg_gen_clean(loading_date, loading_time) function to process power generation data for the specified date and time.\n",
        "\n",
        "7) Calls the select_transform(df, time) function to transform and select the satellite data for the specified time.\n",
        "\n",
        "8) Calls the create_map(satalight) function to create a map visualization based on the transformed satellite data and power generation data.\n",
        "\n",
        "9) After processing the current timestamp, it increments the time by 5 minutes and combines the date and time components to prepare for the next iteration.\n",
        "\n",
        "10) The loop continues until completing the 24-hour cycle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0682404a",
      "metadata": {
        "scrolled": true,
        "id": "0682404a"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "# Set the initial time\n",
        "time = \"2021-04-25T23:55:00\"\n",
        "\n",
        "# Iterate through 5-minute intervals until the end of the 24-hour cycle\n",
        "while time <= \"2021-04-25T23:55:00\":\n",
        "    # Extract the date component\n",
        "    loading_date = time[:10]\n",
        "\n",
        "    # Convert the date component to a datetime object\n",
        "    loading_date_dt = datetime.datetime.strptime(loading_date, \"%Y-%m-%d\")\n",
        "\n",
        "    # Format the date component in the desired format\n",
        "    loading_date_formatted = loading_date_dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # Extract the time component\n",
        "    loading_time = time[11:]\n",
        "    print(\"loading_date:\", loading_date_formatted)\n",
        "    print(\"loading_time:\", loading_time)\n",
        "\n",
        "    # Calling functions\n",
        "    df = load_data(time)\n",
        "\n",
        "    # Check if the timestamp is present in the dataframe\n",
        "    if df is None:\n",
        "        print(\"Timestamp not found in the dataframe. Moving to the next timestamp.\")\n",
        "        # Increment the time by 5 minutes\n",
        "        loading_time_dt = datetime.datetime.strptime(loading_time, \"%H:%M:%S\")\n",
        "        loading_time_dt += datetime.timedelta(minutes=5)\n",
        "        loading_time = loading_time_dt.strftime(\"%H:%M:%S\")\n",
        "\n",
        "        # Combine the date and time components\n",
        "        time = loading_date + \"T\" + loading_time\n",
        "        continue\n",
        "\n",
        "    pw_gen_gdf = pwg_gen_clean(loading_date, loading_time)\n",
        "    satalight = select_transform(df, time).reset_index()\n",
        "    create_map(satalight)\n",
        "\n",
        "    # Increment the time by 5 minutes\n",
        "    loading_time_dt = datetime.datetime.strptime(loading_time, \"%H:%M:%S\")\n",
        "    loading_time_dt += datetime.timedelta(minutes=5)\n",
        "    loading_time = loading_time_dt.strftime(\"%H:%M:%S\")\n",
        "\n",
        "    # Combine the date and time components\n",
        "    time = loading_date + \"T\" + loading_time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5845dd11",
      "metadata": {
        "id": "5845dd11"
      },
      "source": [
        "*There are missing date included in the dataframe, some days are missing a substantian amount of data, for example June 2 2021\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69a487fd",
      "metadata": {
        "id": "69a487fd"
      },
      "source": [
        "### CONVERT TO PNG & CREATE VIDEO\n",
        "\n",
        "This code automates the process of capturing screenshots of web pages, adding custom text, cropping the images, and creating a video from the processed images.\n",
        "\n",
        "For each HTML file:\n",
        "1) Loads the HTML file in the browser\n",
        "2) Captures a screenshot of the web page and saves it as a PNG file.\n",
        "3) Opens the PNG image and crops the image to a specific region, adds text specifying the time, and saves the modified image.\n",
        "4) Creates a video from the generated PNG images by writing each image as a frame in the video.\n",
        "\n",
        "#### REPLACE PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27678cdc",
      "metadata": {
        "id": "27678cdc"
      },
      "outputs": [],
      "source": [
        "# Define paths to data\n",
        "html_path = PATH # replace with input path (where the html files were saved from the\n",
        "output_path = PATH #replace with output path\n",
        "video_name = 'JAN01' # repalce with video name in the format JAN01 for example\n",
        "\n",
        "# Configure Selenium web driver\n",
        "driver = webdriver.Chrome()  # Replace with the appropriate driver for your browser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f05b5e",
      "metadata": {
        "id": "d6f05b5e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from datetime import datetime\n",
        "from selenium import webdriver\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7125d29f",
      "metadata": {
        "id": "7125d29f"
      },
      "outputs": [],
      "source": [
        "# Create the output folder\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "# Get the list of HTML files in the folder\n",
        "html_files = [f for f in os.listdir(html_path) if f.endswith('.html')]\n",
        "\n",
        "for html_file in html_files:\n",
        "    # Set the input and output file paths\n",
        "    input_file = os.path.join(html_path, html_file)\n",
        "\n",
        "    # Extract the time value from the file name\n",
        "    time_str = os.path.splitext(html_file)[0].split(\"map_\")[1]\n",
        "    time = datetime.strptime(time_str, \"%Y-%m-%dT%H_%M_%S\").strftime(\"%H_%M\")\n",
        "\n",
        "    # Create the output file name with the time value\n",
        "    output_file = os.path.join(output_path, f\"{time}.png\")\n",
        "\n",
        "    # Load the HTML file in the browser\n",
        "    driver.get(f\"file://{input_file}\")\n",
        "\n",
        "    # Capture a screenshot of the web page\n",
        "    driver.save_screenshot(output_file)\n",
        "\n",
        "    # Open the generated PNG image\n",
        "    image = Image.open(output_file)\n",
        "\n",
        "    # Define the crop region coordinates (left, upper, right, lower)\n",
        "    left = 52\n",
        "    upper = 52\n",
        "    right = min(image.width, 5000)\n",
        "    lower = min(image.height, 5000)\n",
        "    crop_region = (left, upper, right, lower)\n",
        "\n",
        "    # Crop the image using the defined region\n",
        "    image = image.crop(crop_region)\n",
        "\n",
        "    # Add custom text to the image\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    font = ImageFont.truetype(\"courbd.ttf\", 15)\n",
        "    text = f\"TIME:{time.replace('_', ':')}\"\n",
        "    draw.text((100, 100), text, fill=(0, 0, 0), font=font)\n",
        "\n",
        "    # Save the modified image\n",
        "    image.save(output_file)\n",
        "\n",
        "# Close the browser and quit the driver\n",
        "driver.quit()\n",
        "\n",
        "# Create the video from the generated images\n",
        "image_folder = output_path\n",
        "video_name = os.path.join(output_path, f\"{video_name}.avi\")\n",
        "\n",
        "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
        "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "fps = 24  # Desired frame rate\n",
        "\n",
        "# Define the FourCC code for the codec (in this case, XVID)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "video = cv2.VideoWriter(video_name, fourcc, fps, (width, height))\n",
        "\n",
        "for image in images:\n",
        "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "829aec98",
      "metadata": {
        "id": "829aec98"
      },
      "source": [
        "## TESTING\n",
        "\n",
        "This section is provided to enable users to evaluate the performance of the cloud coverage mask. There may be situations where the cloud coverage image does not accurately display clouds, resulting in a white cast over the video. The purpose of this section is to verify that such issues are not caused by the processing steps, but rather reflect the original data. By conducting tests in this section, users can ensure the integrity of the generated images and assess the accuracy of the cloud representation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e88856",
      "metadata": {
        "id": "38e88856"
      },
      "outputs": [],
      "source": [
        "# Set the initial time\n",
        "time = \"2021-01-01T05:40:00\"\n",
        "\n",
        "# Extract the date component\n",
        "loading_date = time[:10]\n",
        "\n",
        "# Convert the date component to a datetime object\n",
        "loading_date_dt = datetime.strptime(loading_date, \"%Y-%m-%d\")\n",
        "\n",
        "# Format the date component in the desired format\n",
        "loading_date_formatted = loading_date_dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# Extract the time component\n",
        "loading_time = time[11:]\n",
        "print(\"loading_date:\", loading_date_formatted)\n",
        "print(\"loading_time:\", loading_time)\n",
        "\n",
        "# Call the functions to prepair data\n",
        "df = load_data(time)\n",
        "pw_gen_gdf = pwg_gen_clean(loading_date, loading_time)\n",
        "satalight = select_transform(df, time).reset_index()\n",
        "\n",
        "# Load the immages\n",
        "image = np.array(satalight['data'])\n",
        "image_gray = image.reshape((891, 1843))\n",
        "\n",
        "# Apply an appropriate threshold to segment the clouds\n",
        "image_gray_normalized = image_gray / image_gray.max()\n",
        "threshold = 0.2\n",
        "cloud_mask = image_gray_normalized > threshold\n",
        "\n",
        "# Extract the cloud region from the original image\n",
        "cloud_image = image_gray.copy()\n",
        "cloud_image[~cloud_mask] = 0\n",
        "\n",
        "# Create a copy of the cloud image with transparent background\n",
        "transparent_cloud_image = np.zeros((cloud_image.shape[0], cloud_image.shape[1], 4), dtype=np.uint8)\n",
        "transparent_cloud_image[..., 2] = cloud_image\n",
        "transparent_cloud_image[..., 3] = cloud_mask.astype(np.uint8) * 255\n",
        "\n",
        "plt.imshow(cloud_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c790e60f",
      "metadata": {
        "id": "c790e60f"
      },
      "outputs": [],
      "source": [
        "plt.imshow(cloud_mask)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
